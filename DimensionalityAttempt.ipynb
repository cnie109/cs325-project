{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84def00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "Performed so badly that it wasn't even worth including in the presentation or report\n",
    "\n",
    "Leaving it here because I can\n",
    "\n",
    "I will not be commenting or cleaning up any of it\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56119528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRun once ever\\n\\nDownloads and extracts the dataset\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run once ever\n",
    "\n",
    "Downloads and extracts the dataset\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# import urllib.request\n",
    "# import tarfile\n",
    "# import os\n",
    "\n",
    "# mp3file = urllib.request.urlopen(\"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\")\n",
    "# with open('tmp','wb') as output:\n",
    "#   output.write(mp3file.read())\n",
    "\n",
    "# file = tarfile.open(\"tmp\")\n",
    "# file.extractall(\".\")\n",
    "# file.close()\n",
    "# os.remove(\"tmp\")\n",
    "# os.remove(\"cifar-100-python/file.txt~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2634cd0d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-05T22:36:43.035205Z",
     "iopub.status.busy": "2022-12-05T22:36:43.034001Z",
     "iopub.status.idle": "2022-12-05T22:36:51.385205Z",
     "shell.execute_reply": "2022-12-05T22:36:51.383857Z"
    },
    "papermill": {
     "duration": 8.363453,
     "end_time": "2022-12-05T22:36:51.388522",
     "exception": false,
     "start_time": "2022-12-05T22:36:43.025069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import threading\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a02b201",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:36:51.403352Z",
     "iopub.status.busy": "2022-12-05T22:36:51.402523Z",
     "iopub.status.idle": "2022-12-05T22:36:51.409344Z",
     "shell.execute_reply": "2022-12-05T22:36:51.407987Z"
    },
    "papermill": {
     "duration": 0.01862,
     "end_time": "2022-12-05T22:36:51.413400",
     "exception": false,
     "start_time": "2022-12-05T22:36:51.394780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to read files present in the Python version of the dataset\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        myDict = pickle.load(fo, encoding='latin1')\n",
    "    return myDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "294082a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:36:51.428120Z",
     "iopub.status.busy": "2022-12-05T22:36:51.427156Z",
     "iopub.status.idle": "2022-12-05T22:36:54.758676Z",
     "shell.execute_reply": "2022-12-05T22:36:54.757443Z"
    },
    "papermill": {
     "duration": 3.341827,
     "end_time": "2022-12-05T22:36:54.761533",
     "exception": false,
     "start_time": "2022-12-05T22:36:51.419706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filenames <class 'list'>\n",
      "batch_label <class 'str'>\n",
      "fine_labels <class 'list'>\n",
      "coarse_labels <class 'list'>\n",
      "data <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "trainData = unpickle('./cifar-100-python/train')\n",
    "#type of items in each file\n",
    "for item in trainData:\n",
    "    print(item, type(trainData[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9412666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:36:54.776765Z",
     "iopub.status.busy": "2022-12-05T22:36:54.775124Z",
     "iopub.status.idle": "2022-12-05T22:36:55.094446Z",
     "shell.execute_reply": "2022-12-05T22:36:55.092950Z"
    },
    "papermill": {
     "duration": 0.329562,
     "end_time": "2022-12-05T22:36:55.097345",
     "exception": false,
     "start_time": "2022-12-05T22:36:54.767783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine labels: ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm'] \n",
      "\n",
      "Coarse labels: ['aquatic_mammals', 'fish', 'flowers', 'food_containers', 'fruit_and_vegetables', 'household_electrical_devices', 'household_furniture', 'insects', 'large_carnivores', 'large_man-made_outdoor_things', 'large_natural_outdoor_scenes', 'large_omnivores_and_herbivores', 'medium_mammals', 'non-insect_invertebrates', 'people', 'reptiles', 'small_mammals', 'trees', 'vehicles_1', 'vehicles_2']\n"
     ]
    }
   ],
   "source": [
    "testData = unpickle('./cifar-100-python//test')\n",
    "metaData = unpickle('./cifar-100-python//meta')\n",
    "#metaData\n",
    "print(\"Fine labels:\", metaData['fine_label_names'], \"\\n\")\n",
    "print(\"Coarse labels:\", metaData['coarse_label_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09a11b7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:36:55.112096Z",
     "iopub.status.busy": "2022-12-05T22:36:55.111644Z",
     "iopub.status.idle": "2022-12-05T22:36:55.135075Z",
     "shell.execute_reply": "2022-12-05T22:36:55.133571Z"
    },
    "papermill": {
     "duration": 0.034174,
     "end_time": "2022-12-05T22:36:55.137988",
     "exception": false,
     "start_time": "2022-12-05T22:36:55.103814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         SubClass\n",
      "0           apple\n",
      "1   aquarium_fish\n",
      "2            baby\n",
      "3            bear\n",
      "4          beaver\n",
      "..            ...\n",
      "95          whale\n",
      "96    willow_tree\n",
      "97           wolf\n",
      "98          woman\n",
      "99           worm\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#storing fine labels along with its number code in a dataframe\n",
    "subCategory = pd.DataFrame(metaData['fine_label_names'], columns=['SubClass'])\n",
    "print(subCategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b975d0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:36:55.152854Z",
     "iopub.status.busy": "2022-12-05T22:36:55.152064Z",
     "iopub.status.idle": "2022-12-05T22:36:55.157934Z",
     "shell.execute_reply": "2022-12-05T22:36:55.157015Z"
    },
    "papermill": {
     "duration": 0.016292,
     "end_time": "2022-12-05T22:36:55.160644",
     "exception": false,
     "start_time": "2022-12-05T22:36:55.144352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I'm pretty sure this is set up so that dimension 0 is the category\n",
    "X_train = trainData['data']\n",
    "X_train = X_train.reshape(len(X_train),3,32,32).transpose(0,2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3b43585",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:36:55.176063Z",
     "iopub.status.busy": "2022-12-05T22:36:55.175183Z",
     "iopub.status.idle": "2022-12-05T22:36:55.181052Z",
     "shell.execute_reply": "2022-12-05T22:36:55.180139Z"
    },
    "papermill": {
     "duration": 0.016486,
     "end_time": "2022-12-05T22:36:55.183794",
     "exception": false,
     "start_time": "2022-12-05T22:36:55.167308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = testData['data']\n",
    "X_test = X_test.reshape(len(X_test),3,32,32).transpose(0,2,3,1)\n",
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca500110",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:36:55.364228Z",
     "iopub.status.busy": "2022-12-05T22:36:55.362245Z",
     "iopub.status.idle": "2022-12-05T22:36:55.370018Z",
     "shell.execute_reply": "2022-12-05T22:36:55.369133Z"
    },
    "papermill": {
     "duration": 0.028447,
     "end_time": "2022-12-05T22:36:55.372377",
     "exception": false,
     "start_time": "2022-12-05T22:36:55.343930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "winSize = (32,32)\n",
    "blockSize = (8,8)\n",
    "blockStride = (4,4)\n",
    "cellSize = (2, 2)\n",
    "nbins = 12\n",
    "\n",
    "\n",
    "df = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67ad2be",
   "metadata": {
    "papermill": {
     "duration": 0.006098,
     "end_time": "2022-12-05T22:36:55.385268",
     "exception": false,
     "start_time": "2022-12-05T22:36:55.379170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Create Database of HOGs** \n",
    "(Pandas dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb3cec24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:36:55.400842Z",
     "iopub.status.busy": "2022-12-05T22:36:55.399532Z",
     "iopub.status.idle": "2022-12-05T22:37:00.121244Z",
     "shell.execute_reply": "2022-12-05T22:37:00.119975Z"
    },
    "papermill": {
     "duration": 4.732446,
     "end_time": "2022-12-05T22:37:00.124314",
     "exception": false,
     "start_time": "2022-12-05T22:36:55.391868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is essentially where we fit the model\n",
    "DF = []\n",
    "for i in range(len(X_train)):\n",
    "# for i in range(5000):\n",
    "    image = cv2.cvtColor(X_train[i], cv2.COLOR_BGR2GRAY)\n",
    "    hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)\n",
    "    df.append(hog.compute(image))\n",
    "DF = np.array(df)\n",
    "df = []\n",
    "for i in range(len(X_test)):\n",
    "    image = cv2.cvtColor(X_test[i], cv2.COLOR_BGR2GRAY)\n",
    "    hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)\n",
    "    df.append(hog.compute(image))\n",
    "DF_test = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "514bd07d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:37:00.140031Z",
     "iopub.status.busy": "2022-12-05T22:37:00.139616Z",
     "iopub.status.idle": "2022-12-05T22:37:00.176194Z",
     "shell.execute_reply": "2022-12-05T22:37:00.174981Z"
    },
    "papermill": {
     "duration": 0.047191,
     "end_time": "2022-12-05T22:37:00.179019",
     "exception": false,
     "start_time": "2022-12-05T22:37:00.131828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.00412205, ..., 0.00682359, 0.0028279 ,\n",
       "       0.06439196], shape=(9408,), dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465d65c5",
   "metadata": {
    "papermill": {
     "duration": 0.006739,
     "end_time": "2022-12-05T22:37:00.193374",
     "exception": false,
     "start_time": "2022-12-05T22:37:00.186635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "****continue work checkpoint: standardize test data and proceed****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbdbf225",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:37:00.210462Z",
     "iopub.status.busy": "2022-12-05T22:37:00.210011Z",
     "iopub.status.idle": "2022-12-05T22:37:00.219912Z",
     "shell.execute_reply": "2022-12-05T22:37:00.218503Z"
    },
    "papermill": {
     "duration": 0.021869,
     "end_time": "2022-12-05T22:37:00.222796",
     "exception": false,
     "start_time": "2022-12-05T22:37:00.200927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(img, k, winSize, blockSize, blockStride, cellSize, nbins):\n",
    "    \n",
    "    #Extract sample's features\n",
    "    # sample = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)\n",
    "    # _hog = hog.compute(sample)\n",
    "    \n",
    "    #Get Nearest Neighbors\n",
    "    distances = []\n",
    "    for i in range(len(DF)):\n",
    "        distances.append(np.linalg.norm(img - X_train[i]))         # 1- Calculate and store each datapoint's Euclidean distance\n",
    "    # distances = np.linalg.norm((np.expand_dims(_hog, axis=0) - DF))\n",
    "    \n",
    "    kNNsID = np.argsort(distances)[:k]                              # 2- Sort distances' IDs in an ascending order\n",
    "    \n",
    "    kNNsCats = []\n",
    "    for i in kNNsID:\n",
    "        kNNsCats.append(subCategory.iloc[trainData['fine_labels'][i]][0].capitalize())      # 3- Get categories of each of the NNs\n",
    "    \n",
    "    CommonCat = Counter(kNNsCats).most_common(1)                    # 4- Count and get Most common category\n",
    "    \n",
    "    return CommonCat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62a72650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:37:00.240362Z",
     "iopub.status.busy": "2022-12-05T22:37:00.239906Z",
     "iopub.status.idle": "2022-12-05T22:37:01.502388Z",
     "shell.execute_reply": "2022-12-05T22:37:01.501222Z"
    },
    "papermill": {
     "duration": 1.274702,
     "end_time": "2022-12-05T22:37:01.505182",
     "exception": false,
     "start_time": "2022-12-05T22:37:00.230480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_185303/2195589398.py:18: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  kNNsCats.append(subCategory.iloc[trainData['fine_labels'][i]][0].capitalize())      # 3- Get categories of each of the NNs\n"
     ]
    }
   ],
   "source": [
    "n = 25\n",
    "p = predict(X_test[n], 20, winSize, blockSize, blockStride, cellSize, nbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eec345b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:37:01.521033Z",
     "iopub.status.busy": "2022-12-05T22:37:01.520613Z",
     "iopub.status.idle": "2022-12-05T22:37:01.527966Z",
     "shell.execute_reply": "2022-12-05T22:37:01.526857Z"
    },
    "papermill": {
     "duration": 0.018099,
     "end_time": "2022-12-05T22:37:01.530285",
     "exception": false,
     "start_time": "2022-12-05T22:37:01.512186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getAccuracy(k, x_test, testdata, winSize, blockSize, blockStride, cellSize, nbins):\n",
    "    preds = []\n",
    "    RightCount = 0\n",
    "    for i in range(1000):\n",
    "        pred = predict(x_test[i], k, winSize, blockSize, blockStride, cellSize, nbins)\n",
    "        if pred[0][0] == subCategory.iloc[testdata['fine_labels'][i]][0].capitalize():\n",
    "            RightCount += 1\n",
    "        preds.append(pred)\n",
    "        print(\"Done: {}, Accuracy: {}\".format(i,(RightCount/(i+1))*100), flush=True)\n",
    "    # it would be RightCount / 1000 * 100, so I just made it RightCount / 10\n",
    "    return RightCount / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2162e044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 12480)\n",
      "(10000, 12480)\n"
     ]
    }
   ],
   "source": [
    "y_train = trainData[\"fine_labels\"]\n",
    "y_test = testData[\"fine_labels\"]\n",
    "X_train = trainData[\"data\"]\n",
    "X_test = testData[\"data\"]\n",
    "\n",
    "# X_train = np.array(pd.concat([pd.DataFrame(X_train), DF], axis=1))\n",
    "# X_test = np.array(pd.concat([pd.DataFrame(X_test), DF_test], axis=1))\n",
    "X_train = np.concat([X_train, DF], axis=1)\n",
    "X_test = np.concat([X_test, DF_test], axis=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40edeb6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:37:01.546678Z",
     "iopub.status.busy": "2022-12-05T22:37:01.546173Z",
     "iopub.status.idle": "2022-12-05T22:58:03.115385Z",
     "shell.execute_reply": "2022-12-05T22:58:03.114403Z"
    },
    "papermill": {
     "duration": 1261.580274,
     "end_time": "2022-12-05T22:58:03.117685",
     "exception": false,
     "start_time": "2022-12-05T22:37:01.537411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 0, Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_185303/2195589398.py:18: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  kNNsCats.append(subCategory.iloc[trainData['fine_labels'][i]][0].capitalize())      # 3- Get categories of each of the NNs\n",
      "/tmp/ipykernel_185303/703372369.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if pred[0][0] == subCategory.iloc[testdata['fine_labels'][i]][0].capitalize():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 1, Accuracy: 0.0\n",
      "Done: 2, Accuracy: 0.0\n",
      "Done: 3, Accuracy: 0.0\n",
      "Done: 4, Accuracy: 0.0\n",
      "Done: 5, Accuracy: 0.0\n",
      "Done: 6, Accuracy: 0.0\n",
      "Done: 7, Accuracy: 0.0\n",
      "Done: 8, Accuracy: 0.0\n",
      "Done: 9, Accuracy: 0.0\n",
      "Done: 10, Accuracy: 0.0\n",
      "Done: 11, Accuracy: 0.0\n",
      "Done: 12, Accuracy: 0.0\n",
      "Done: 13, Accuracy: 0.0\n",
      "Done: 14, Accuracy: 0.0\n",
      "Done: 15, Accuracy: 0.0\n",
      "Done: 16, Accuracy: 0.0\n",
      "Done: 17, Accuracy: 0.0\n",
      "Done: 18, Accuracy: 0.0\n",
      "Done: 19, Accuracy: 0.0\n",
      "Done: 20, Accuracy: 0.0\n",
      "Done: 21, Accuracy: 0.0\n",
      "Done: 22, Accuracy: 0.0\n",
      "Done: 23, Accuracy: 0.0\n",
      "Done: 24, Accuracy: 0.0\n",
      "Done: 25, Accuracy: 0.0\n",
      "Done: 26, Accuracy: 0.0\n",
      "Done: 27, Accuracy: 0.0\n",
      "Done: 28, Accuracy: 0.0\n",
      "Done: 29, Accuracy: 0.0\n",
      "Done: 30, Accuracy: 0.0\n",
      "Done: 31, Accuracy: 0.0\n",
      "Done: 32, Accuracy: 0.0\n",
      "Done: 33, Accuracy: 0.0\n",
      "Done: 34, Accuracy: 0.0\n",
      "Done: 35, Accuracy: 0.0\n",
      "Done: 36, Accuracy: 0.0\n",
      "Done: 37, Accuracy: 0.0\n",
      "Done: 38, Accuracy: 0.0\n",
      "Done: 39, Accuracy: 0.0\n",
      "Done: 40, Accuracy: 0.0\n",
      "Done: 41, Accuracy: 0.0\n",
      "Done: 42, Accuracy: 0.0\n",
      "Done: 43, Accuracy: 0.0\n",
      "Done: 44, Accuracy: 0.0\n",
      "Done: 45, Accuracy: 0.0\n",
      "Done: 46, Accuracy: 0.0\n",
      "Done: 47, Accuracy: 0.0\n",
      "Done: 48, Accuracy: 0.0\n",
      "Done: 49, Accuracy: 0.0\n",
      "Done: 50, Accuracy: 0.0\n",
      "Done: 51, Accuracy: 0.0\n",
      "Done: 52, Accuracy: 0.0\n",
      "Done: 53, Accuracy: 0.0\n",
      "Done: 54, Accuracy: 0.0\n",
      "Done: 55, Accuracy: 0.0\n",
      "Done: 56, Accuracy: 0.0\n",
      "Done: 57, Accuracy: 0.0\n",
      "Done: 58, Accuracy: 0.0\n",
      "Done: 59, Accuracy: 0.0\n",
      "Done: 60, Accuracy: 0.0\n",
      "Done: 61, Accuracy: 0.0\n",
      "Done: 62, Accuracy: 0.0\n",
      "Done: 63, Accuracy: 0.0\n",
      "Done: 64, Accuracy: 0.0\n",
      "Done: 65, Accuracy: 0.0\n",
      "Done: 66, Accuracy: 0.0\n",
      "Done: 67, Accuracy: 0.0\n",
      "Done: 68, Accuracy: 0.0\n",
      "Done: 69, Accuracy: 0.0\n",
      "Done: 70, Accuracy: 0.0\n",
      "Done: 71, Accuracy: 0.0\n",
      "Done: 72, Accuracy: 0.0\n",
      "Done: 73, Accuracy: 0.0\n",
      "Done: 74, Accuracy: 0.0\n",
      "Done: 75, Accuracy: 0.0\n",
      "Done: 76, Accuracy: 0.0\n",
      "Done: 77, Accuracy: 0.0\n",
      "Done: 78, Accuracy: 0.0\n",
      "Done: 79, Accuracy: 0.0\n",
      "Done: 80, Accuracy: 0.0\n",
      "Done: 81, Accuracy: 0.0\n",
      "Done: 82, Accuracy: 0.0\n",
      "Done: 83, Accuracy: 0.0\n",
      "Done: 84, Accuracy: 0.0\n",
      "Done: 85, Accuracy: 0.0\n",
      "Done: 86, Accuracy: 0.0\n",
      "Done: 87, Accuracy: 0.0\n",
      "Done: 88, Accuracy: 0.0\n",
      "Done: 89, Accuracy: 0.0\n",
      "Done: 90, Accuracy: 0.0\n",
      "Done: 91, Accuracy: 0.0\n",
      "Done: 92, Accuracy: 0.0\n",
      "Done: 93, Accuracy: 0.0\n",
      "Done: 94, Accuracy: 0.0\n",
      "Done: 95, Accuracy: 0.0\n",
      "Done: 96, Accuracy: 0.0\n",
      "Done: 97, Accuracy: 0.0\n",
      "Done: 98, Accuracy: 0.0\n",
      "Done: 99, Accuracy: 0.0\n",
      "Done: 100, Accuracy: 0.0\n",
      "Done: 101, Accuracy: 0.0\n",
      "Done: 102, Accuracy: 0.0\n",
      "Done: 103, Accuracy: 0.0\n",
      "Done: 104, Accuracy: 0.0\n",
      "Done: 105, Accuracy: 0.0\n",
      "Done: 106, Accuracy: 0.0\n",
      "Done: 107, Accuracy: 0.0\n",
      "Done: 108, Accuracy: 0.0\n",
      "Done: 109, Accuracy: 0.0\n",
      "Done: 110, Accuracy: 0.0\n",
      "Done: 111, Accuracy: 0.0\n",
      "Done: 112, Accuracy: 0.0\n",
      "Done: 113, Accuracy: 0.0\n",
      "Done: 114, Accuracy: 0.0\n",
      "Done: 115, Accuracy: 0.0\n",
      "Done: 116, Accuracy: 0.0\n",
      "Done: 117, Accuracy: 0.0\n",
      "Done: 118, Accuracy: 0.0\n",
      "Done: 119, Accuracy: 0.0\n",
      "Done: 120, Accuracy: 0.0\n",
      "Done: 121, Accuracy: 0.0\n",
      "Done: 122, Accuracy: 0.0\n",
      "Done: 123, Accuracy: 0.0\n",
      "Done: 124, Accuracy: 0.0\n",
      "Done: 125, Accuracy: 0.0\n",
      "Done: 126, Accuracy: 0.0\n",
      "Done: 127, Accuracy: 0.0\n",
      "Done: 128, Accuracy: 0.0\n",
      "Done: 129, Accuracy: 0.0\n",
      "Done: 130, Accuracy: 0.0\n",
      "Done: 131, Accuracy: 0.0\n",
      "Done: 132, Accuracy: 0.0\n",
      "Done: 133, Accuracy: 0.0\n",
      "Done: 134, Accuracy: 0.0\n",
      "Done: 135, Accuracy: 0.0\n",
      "Done: 136, Accuracy: 0.0\n",
      "Done: 137, Accuracy: 0.0\n",
      "Done: 138, Accuracy: 0.0\n",
      "Done: 139, Accuracy: 0.0\n",
      "Done: 140, Accuracy: 0.0\n",
      "Done: 141, Accuracy: 0.0\n",
      "Done: 142, Accuracy: 0.0\n",
      "Done: 143, Accuracy: 0.0\n",
      "Done: 144, Accuracy: 0.0\n",
      "Done: 145, Accuracy: 0.0\n",
      "Done: 146, Accuracy: 0.0\n",
      "Done: 147, Accuracy: 0.0\n",
      "Done: 148, Accuracy: 0.0\n",
      "Done: 149, Accuracy: 0.0\n",
      "Done: 150, Accuracy: 0.0\n",
      "Done: 151, Accuracy: 0.0\n",
      "Done: 152, Accuracy: 0.0\n",
      "Done: 153, Accuracy: 0.0\n",
      "Done: 154, Accuracy: 0.6451612903225806\n",
      "Done: 155, Accuracy: 0.641025641025641\n",
      "Done: 156, Accuracy: 0.6369426751592357\n",
      "Done: 157, Accuracy: 0.6329113924050633\n",
      "Done: 158, Accuracy: 0.628930817610063\n",
      "Done: 159, Accuracy: 0.625\n",
      "Done: 160, Accuracy: 0.6211180124223602\n",
      "Done: 161, Accuracy: 0.6172839506172839\n",
      "Done: 162, Accuracy: 0.6134969325153374\n",
      "Done: 163, Accuracy: 0.6097560975609756\n",
      "Done: 164, Accuracy: 0.6060606060606061\n",
      "Done: 165, Accuracy: 0.6024096385542169\n",
      "Done: 166, Accuracy: 0.5988023952095809\n",
      "Done: 167, Accuracy: 0.5952380952380952\n",
      "Done: 168, Accuracy: 0.591715976331361\n",
      "Done: 169, Accuracy: 0.5882352941176471\n",
      "Done: 170, Accuracy: 0.5847953216374269\n",
      "Done: 171, Accuracy: 0.5813953488372093\n",
      "Done: 172, Accuracy: 0.5780346820809248\n",
      "Done: 173, Accuracy: 0.5747126436781609\n",
      "Done: 174, Accuracy: 0.5714285714285714\n",
      "Done: 175, Accuracy: 0.5681818181818182\n",
      "Done: 176, Accuracy: 0.5649717514124294\n",
      "Done: 177, Accuracy: 0.5617977528089888\n",
      "Done: 178, Accuracy: 0.5586592178770949\n",
      "Done: 179, Accuracy: 0.5555555555555556\n",
      "Done: 180, Accuracy: 0.5524861878453038\n",
      "Done: 181, Accuracy: 0.5494505494505495\n",
      "Done: 182, Accuracy: 0.546448087431694\n",
      "Done: 183, Accuracy: 0.5434782608695652\n",
      "Done: 184, Accuracy: 0.5405405405405406\n",
      "Done: 185, Accuracy: 0.5376344086021506\n",
      "Done: 186, Accuracy: 0.53475935828877\n",
      "Done: 187, Accuracy: 0.5319148936170213\n",
      "Done: 188, Accuracy: 0.5291005291005291\n",
      "Done: 189, Accuracy: 0.5263157894736842\n",
      "Done: 190, Accuracy: 0.5235602094240838\n",
      "Done: 191, Accuracy: 0.5208333333333333\n",
      "Done: 192, Accuracy: 1.0362694300518136\n",
      "Done: 193, Accuracy: 1.0309278350515463\n",
      "Done: 194, Accuracy: 1.0256410256410255\n",
      "Done: 195, Accuracy: 1.0204081632653061\n",
      "Done: 196, Accuracy: 1.015228426395939\n",
      "Done: 197, Accuracy: 1.0101010101010102\n",
      "Done: 198, Accuracy: 1.0050251256281406\n",
      "Done: 199, Accuracy: 1.0\n",
      "Done: 200, Accuracy: 0.9950248756218906\n",
      "Done: 201, Accuracy: 0.9900990099009901\n",
      "Done: 202, Accuracy: 0.9852216748768473\n",
      "Done: 203, Accuracy: 0.9803921568627451\n",
      "Done: 204, Accuracy: 0.975609756097561\n",
      "Done: 205, Accuracy: 0.9708737864077669\n",
      "Done: 206, Accuracy: 0.966183574879227\n",
      "Done: 207, Accuracy: 0.9615384615384616\n",
      "Done: 208, Accuracy: 0.9569377990430622\n",
      "Done: 209, Accuracy: 0.9523809523809524\n",
      "Done: 210, Accuracy: 0.9478672985781991\n",
      "Done: 211, Accuracy: 0.9433962264150944\n",
      "Done: 212, Accuracy: 0.9389671361502347\n",
      "Done: 213, Accuracy: 0.9345794392523363\n",
      "Done: 214, Accuracy: 0.9302325581395349\n",
      "Done: 215, Accuracy: 0.9259259259259258\n",
      "Done: 216, Accuracy: 0.9216589861751152\n",
      "Done: 217, Accuracy: 0.9174311926605505\n",
      "Done: 218, Accuracy: 0.91324200913242\n",
      "Done: 219, Accuracy: 0.9090909090909091\n",
      "Done: 220, Accuracy: 0.904977375565611\n",
      "Done: 221, Accuracy: 0.9009009009009009\n",
      "Done: 222, Accuracy: 0.8968609865470852\n",
      "Done: 223, Accuracy: 0.8928571428571428\n",
      "Done: 224, Accuracy: 0.8888888888888888\n",
      "Done: 225, Accuracy: 0.8849557522123894\n",
      "Done: 226, Accuracy: 0.881057268722467\n",
      "Done: 227, Accuracy: 0.8771929824561403\n",
      "Done: 228, Accuracy: 0.8733624454148471\n",
      "Done: 229, Accuracy: 0.8695652173913043\n",
      "Done: 230, Accuracy: 0.8658008658008658\n",
      "Done: 231, Accuracy: 0.8620689655172413\n",
      "Done: 232, Accuracy: 0.8583690987124464\n",
      "Done: 233, Accuracy: 0.8547008547008548\n",
      "Done: 234, Accuracy: 0.851063829787234\n",
      "Done: 235, Accuracy: 0.847457627118644\n",
      "Done: 236, Accuracy: 0.8438818565400843\n",
      "Done: 237, Accuracy: 0.8403361344537815\n",
      "Done: 238, Accuracy: 0.8368200836820083\n",
      "Done: 239, Accuracy: 0.8333333333333334\n",
      "Done: 240, Accuracy: 0.8298755186721992\n",
      "Done: 241, Accuracy: 0.8264462809917356\n",
      "Done: 242, Accuracy: 0.823045267489712\n",
      "Done: 243, Accuracy: 0.819672131147541\n",
      "Done: 244, Accuracy: 0.8163265306122449\n",
      "Done: 245, Accuracy: 0.8130081300813009\n",
      "Done: 246, Accuracy: 0.8097165991902834\n",
      "Done: 247, Accuracy: 0.8064516129032258\n",
      "Done: 248, Accuracy: 0.8032128514056224\n",
      "Done: 249, Accuracy: 0.8\n",
      "Done: 250, Accuracy: 0.796812749003984\n",
      "Done: 251, Accuracy: 0.7936507936507936\n",
      "Done: 252, Accuracy: 0.7905138339920948\n",
      "Done: 253, Accuracy: 0.7874015748031495\n",
      "Done: 254, Accuracy: 0.7843137254901961\n",
      "Done: 255, Accuracy: 0.78125\n",
      "Done: 256, Accuracy: 0.7782101167315175\n",
      "Done: 257, Accuracy: 0.7751937984496124\n",
      "Done: 258, Accuracy: 0.7722007722007722\n",
      "Done: 259, Accuracy: 0.7692307692307693\n",
      "Done: 260, Accuracy: 0.7662835249042145\n",
      "Done: 261, Accuracy: 0.7633587786259541\n",
      "Done: 262, Accuracy: 0.7604562737642585\n",
      "Done: 263, Accuracy: 0.7575757575757576\n",
      "Done: 264, Accuracy: 0.7547169811320755\n",
      "Done: 265, Accuracy: 0.7518796992481203\n",
      "Done: 266, Accuracy: 0.7490636704119851\n",
      "Done: 267, Accuracy: 0.7462686567164178\n",
      "Done: 268, Accuracy: 0.7434944237918215\n",
      "Done: 269, Accuracy: 0.7407407407407408\n",
      "Done: 270, Accuracy: 0.7380073800738007\n",
      "Done: 271, Accuracy: 0.7352941176470588\n",
      "Done: 272, Accuracy: 0.7326007326007326\n",
      "Done: 273, Accuracy: 0.7299270072992701\n",
      "Done: 274, Accuracy: 0.7272727272727273\n",
      "Done: 275, Accuracy: 0.7246376811594203\n",
      "Done: 276, Accuracy: 0.7220216606498195\n",
      "Done: 277, Accuracy: 0.7194244604316548\n",
      "Done: 278, Accuracy: 0.7168458781362007\n",
      "Done: 279, Accuracy: 0.7142857142857143\n",
      "Done: 280, Accuracy: 0.7117437722419928\n",
      "Done: 281, Accuracy: 0.7092198581560284\n",
      "Done: 282, Accuracy: 0.7067137809187279\n",
      "Done: 283, Accuracy: 0.7042253521126761\n",
      "Done: 284, Accuracy: 0.7017543859649122\n",
      "Done: 285, Accuracy: 0.6993006993006993\n",
      "Done: 286, Accuracy: 0.6968641114982579\n",
      "Done: 287, Accuracy: 0.6944444444444444\n",
      "Done: 288, Accuracy: 0.6920415224913495\n",
      "Done: 289, Accuracy: 0.6896551724137931\n",
      "Done: 290, Accuracy: 0.6872852233676976\n",
      "Done: 291, Accuracy: 0.684931506849315\n",
      "Done: 292, Accuracy: 0.6825938566552902\n",
      "Done: 293, Accuracy: 0.6802721088435374\n",
      "Done: 294, Accuracy: 0.6779661016949152\n",
      "Done: 295, Accuracy: 0.6756756756756757\n",
      "Done: 296, Accuracy: 0.6734006734006733\n",
      "Done: 297, Accuracy: 0.6711409395973155\n",
      "Done: 298, Accuracy: 0.6688963210702341\n",
      "Done: 299, Accuracy: 0.6666666666666667\n",
      "Done: 300, Accuracy: 0.6644518272425249\n",
      "Done: 301, Accuracy: 0.6622516556291391\n",
      "Done: 302, Accuracy: 0.6600660066006601\n",
      "Done: 303, Accuracy: 0.6578947368421052\n",
      "Done: 304, Accuracy: 0.6557377049180327\n",
      "Done: 305, Accuracy: 0.6535947712418301\n",
      "Done: 306, Accuracy: 0.6514657980456027\n",
      "Done: 307, Accuracy: 0.6493506493506493\n",
      "Done: 308, Accuracy: 0.6472491909385114\n",
      "Done: 309, Accuracy: 0.6451612903225806\n",
      "Done: 310, Accuracy: 0.6430868167202572\n",
      "Done: 311, Accuracy: 0.641025641025641\n",
      "Done: 312, Accuracy: 0.6389776357827476\n",
      "Done: 313, Accuracy: 0.6369426751592357\n",
      "Done: 314, Accuracy: 0.6349206349206349\n",
      "Done: 315, Accuracy: 0.6329113924050633\n",
      "Done: 316, Accuracy: 0.6309148264984227\n",
      "Done: 317, Accuracy: 0.628930817610063\n",
      "Done: 318, Accuracy: 0.6269592476489028\n",
      "Done: 319, Accuracy: 0.625\n",
      "Done: 320, Accuracy: 0.6230529595015576\n",
      "Done: 321, Accuracy: 0.6211180124223602\n",
      "Done: 322, Accuracy: 0.6191950464396285\n",
      "Done: 323, Accuracy: 0.6172839506172839\n",
      "Done: 324, Accuracy: 0.6153846153846154\n",
      "Done: 325, Accuracy: 0.6134969325153374\n",
      "Done: 326, Accuracy: 0.6116207951070336\n",
      "Done: 327, Accuracy: 0.6097560975609756\n",
      "Done: 328, Accuracy: 0.60790273556231\n",
      "Done: 329, Accuracy: 0.6060606060606061\n",
      "Done: 330, Accuracy: 0.6042296072507553\n",
      "Done: 331, Accuracy: 0.6024096385542169\n",
      "Done: 332, Accuracy: 0.6006006006006006\n",
      "Done: 333, Accuracy: 0.5988023952095809\n",
      "Done: 334, Accuracy: 0.5970149253731344\n",
      "Done: 335, Accuracy: 0.5952380952380952\n",
      "Done: 336, Accuracy: 0.8902077151335311\n",
      "Done: 337, Accuracy: 0.8875739644970414\n",
      "Done: 338, Accuracy: 0.8849557522123894\n",
      "Done: 339, Accuracy: 0.8823529411764706\n",
      "Done: 340, Accuracy: 0.8797653958944283\n",
      "Done: 341, Accuracy: 0.8771929824561403\n",
      "Done: 342, Accuracy: 0.8746355685131195\n",
      "Done: 343, Accuracy: 0.872093023255814\n",
      "Done: 344, Accuracy: 0.8695652173913043\n",
      "Done: 345, Accuracy: 0.8670520231213872\n",
      "Done: 346, Accuracy: 0.8645533141210375\n",
      "Done: 347, Accuracy: 0.8620689655172413\n",
      "Done: 348, Accuracy: 0.8595988538681949\n",
      "Done: 349, Accuracy: 0.8571428571428572\n",
      "Done: 350, Accuracy: 0.8547008547008548\n",
      "Done: 351, Accuracy: 0.8522727272727272\n",
      "Done: 352, Accuracy: 0.84985835694051\n",
      "Done: 353, Accuracy: 0.847457627118644\n",
      "Done: 354, Accuracy: 0.8450704225352111\n",
      "Done: 355, Accuracy: 0.8426966292134831\n",
      "Done: 356, Accuracy: 0.8403361344537815\n",
      "Done: 357, Accuracy: 0.8379888268156425\n",
      "Done: 358, Accuracy: 0.8356545961002786\n",
      "Done: 359, Accuracy: 0.8333333333333334\n",
      "Done: 360, Accuracy: 0.8310249307479225\n",
      "Done: 361, Accuracy: 0.8287292817679558\n",
      "Done: 362, Accuracy: 0.8264462809917356\n",
      "Done: 363, Accuracy: 0.8241758241758242\n",
      "Done: 364, Accuracy: 0.821917808219178\n",
      "Done: 365, Accuracy: 0.819672131147541\n",
      "Done: 366, Accuracy: 0.8174386920980926\n",
      "Done: 367, Accuracy: 0.8152173913043478\n",
      "Done: 368, Accuracy: 0.8130081300813009\n",
      "Done: 369, Accuracy: 0.8108108108108109\n",
      "Done: 370, Accuracy: 0.8086253369272237\n",
      "Done: 371, Accuracy: 0.8064516129032258\n",
      "Done: 372, Accuracy: 0.8042895442359249\n",
      "Done: 373, Accuracy: 0.8021390374331552\n",
      "Done: 374, Accuracy: 0.8\n",
      "Done: 375, Accuracy: 0.7978723404255319\n",
      "Done: 376, Accuracy: 0.7957559681697612\n",
      "Done: 377, Accuracy: 0.7936507936507936\n",
      "Done: 378, Accuracy: 0.79155672823219\n",
      "Done: 379, Accuracy: 0.7894736842105263\n",
      "Done: 380, Accuracy: 0.7874015748031495\n",
      "Done: 381, Accuracy: 0.7853403141361256\n",
      "Done: 382, Accuracy: 0.7832898172323759\n",
      "Done: 383, Accuracy: 0.78125\n",
      "Done: 384, Accuracy: 0.7792207792207793\n",
      "Done: 385, Accuracy: 0.7772020725388601\n",
      "Done: 386, Accuracy: 0.7751937984496124\n",
      "Done: 387, Accuracy: 0.7731958762886598\n",
      "Done: 388, Accuracy: 0.7712082262210797\n",
      "Done: 389, Accuracy: 0.7692307692307693\n",
      "Done: 390, Accuracy: 0.7672634271099744\n",
      "Done: 391, Accuracy: 0.7653061224489796\n",
      "Done: 392, Accuracy: 0.7633587786259541\n",
      "Done: 393, Accuracy: 0.7614213197969544\n",
      "Done: 394, Accuracy: 0.7594936708860759\n",
      "Done: 395, Accuracy: 0.7575757575757576\n",
      "Done: 396, Accuracy: 0.7556675062972292\n",
      "Done: 397, Accuracy: 0.7537688442211055\n",
      "Done: 398, Accuracy: 0.7518796992481203\n",
      "Done: 399, Accuracy: 0.75\n",
      "Done: 400, Accuracy: 0.7481296758104738\n",
      "Done: 401, Accuracy: 0.7462686567164178\n",
      "Done: 402, Accuracy: 0.7444168734491315\n",
      "Done: 403, Accuracy: 0.7425742574257426\n",
      "Done: 404, Accuracy: 0.7407407407407408\n",
      "Done: 405, Accuracy: 0.7389162561576355\n",
      "Done: 406, Accuracy: 0.7371007371007371\n",
      "Done: 407, Accuracy: 0.7352941176470588\n",
      "Done: 408, Accuracy: 0.7334963325183375\n",
      "Done: 409, Accuracy: 0.7317073170731708\n",
      "Done: 410, Accuracy: 0.7299270072992701\n",
      "Done: 411, Accuracy: 0.7281553398058253\n",
      "Done: 412, Accuracy: 0.7263922518159807\n",
      "Done: 413, Accuracy: 0.7246376811594203\n",
      "Done: 414, Accuracy: 0.7228915662650602\n",
      "Done: 415, Accuracy: 0.7211538461538461\n",
      "Done: 416, Accuracy: 0.7194244604316548\n",
      "Done: 417, Accuracy: 0.7177033492822966\n",
      "Done: 418, Accuracy: 0.7159904534606205\n",
      "Done: 419, Accuracy: 0.7142857142857143\n",
      "Done: 420, Accuracy: 0.7125890736342043\n",
      "Done: 421, Accuracy: 0.7109004739336493\n",
      "Done: 422, Accuracy: 0.7092198581560284\n",
      "Done: 423, Accuracy: 0.7075471698113208\n",
      "Done: 424, Accuracy: 0.7058823529411765\n",
      "Done: 425, Accuracy: 0.7042253521126761\n",
      "Done: 426, Accuracy: 0.702576112412178\n",
      "Done: 427, Accuracy: 0.7009345794392523\n",
      "Done: 428, Accuracy: 0.6993006993006993\n",
      "Done: 429, Accuracy: 0.6976744186046512\n",
      "Done: 430, Accuracy: 0.6960556844547563\n",
      "Done: 431, Accuracy: 0.6944444444444444\n",
      "Done: 432, Accuracy: 0.6928406466512702\n",
      "Done: 433, Accuracy: 0.6912442396313364\n",
      "Done: 434, Accuracy: 0.6896551724137931\n",
      "Done: 435, Accuracy: 0.6880733944954129\n",
      "Done: 436, Accuracy: 0.6864988558352403\n",
      "Done: 437, Accuracy: 0.684931506849315\n",
      "Done: 438, Accuracy: 0.683371298405467\n",
      "Done: 439, Accuracy: 0.6818181818181818\n",
      "Done: 440, Accuracy: 0.6802721088435374\n",
      "Done: 441, Accuracy: 0.6787330316742082\n",
      "Done: 442, Accuracy: 0.6772009029345373\n",
      "Done: 443, Accuracy: 0.6756756756756757\n",
      "Done: 444, Accuracy: 0.6741573033707865\n",
      "Done: 445, Accuracy: 0.672645739910314\n",
      "Done: 446, Accuracy: 0.6711409395973155\n",
      "Done: 447, Accuracy: 0.6696428571428571\n",
      "Done: 448, Accuracy: 0.6681514476614699\n",
      "Done: 449, Accuracy: 0.6666666666666667\n",
      "Done: 450, Accuracy: 0.6651884700665188\n",
      "Done: 451, Accuracy: 0.6637168141592921\n",
      "Done: 452, Accuracy: 0.6622516556291391\n",
      "Done: 453, Accuracy: 0.6607929515418502\n",
      "Done: 454, Accuracy: 0.6593406593406593\n",
      "Done: 455, Accuracy: 0.6578947368421052\n",
      "Done: 456, Accuracy: 0.6564551422319475\n",
      "Done: 457, Accuracy: 0.6550218340611353\n",
      "Done: 458, Accuracy: 0.6535947712418301\n",
      "Done: 459, Accuracy: 0.6521739130434783\n",
      "Done: 460, Accuracy: 0.6507592190889371\n",
      "Done: 461, Accuracy: 0.6493506493506493\n",
      "Done: 462, Accuracy: 0.6479481641468683\n",
      "Done: 463, Accuracy: 0.646551724137931\n",
      "Done: 464, Accuracy: 0.6451612903225806\n",
      "Done: 465, Accuracy: 0.6437768240343348\n",
      "Done: 466, Accuracy: 0.6423982869379015\n",
      "Done: 467, Accuracy: 0.641025641025641\n",
      "Done: 468, Accuracy: 0.6396588486140725\n",
      "Done: 469, Accuracy: 0.6382978723404255\n",
      "Done: 470, Accuracy: 0.6369426751592357\n",
      "Done: 471, Accuracy: 0.6355932203389831\n",
      "Done: 472, Accuracy: 0.6342494714587738\n",
      "Done: 473, Accuracy: 0.6329113924050633\n",
      "Done: 474, Accuracy: 0.631578947368421\n",
      "Done: 475, Accuracy: 0.6302521008403361\n",
      "Done: 476, Accuracy: 0.628930817610063\n",
      "Done: 477, Accuracy: 0.6276150627615062\n",
      "Done: 478, Accuracy: 0.6263048016701461\n",
      "Done: 479, Accuracy: 0.625\n",
      "Done: 480, Accuracy: 0.6237006237006237\n",
      "Done: 481, Accuracy: 0.6224066390041494\n",
      "Done: 482, Accuracy: 0.6211180124223602\n",
      "Done: 483, Accuracy: 0.6198347107438017\n",
      "Done: 484, Accuracy: 0.6185567010309279\n",
      "Done: 485, Accuracy: 0.6172839506172839\n",
      "Done: 486, Accuracy: 0.6160164271047228\n",
      "Done: 487, Accuracy: 0.6147540983606558\n",
      "Done: 488, Accuracy: 0.6134969325153374\n",
      "Done: 489, Accuracy: 0.6122448979591837\n",
      "Done: 490, Accuracy: 0.6109979633401221\n",
      "Done: 491, Accuracy: 0.6097560975609756\n",
      "Done: 492, Accuracy: 0.6085192697768762\n",
      "Done: 493, Accuracy: 0.6072874493927125\n",
      "Done: 494, Accuracy: 0.6060606060606061\n",
      "Done: 495, Accuracy: 0.6048387096774194\n",
      "Done: 496, Accuracy: 0.6036217303822937\n",
      "Done: 497, Accuracy: 0.6024096385542169\n",
      "Done: 498, Accuracy: 0.6012024048096193\n",
      "Done: 499, Accuracy: 0.6\n",
      "Done: 500, Accuracy: 0.5988023952095809\n",
      "Done: 501, Accuracy: 0.5976095617529881\n",
      "Done: 502, Accuracy: 0.5964214711729622\n",
      "Done: 503, Accuracy: 0.5952380952380952\n",
      "Done: 504, Accuracy: 0.594059405940594\n",
      "Done: 505, Accuracy: 0.592885375494071\n",
      "Done: 506, Accuracy: 0.591715976331361\n",
      "Done: 507, Accuracy: 0.5905511811023622\n",
      "Done: 508, Accuracy: 0.5893909626719057\n",
      "Done: 509, Accuracy: 0.5882352941176471\n",
      "Done: 510, Accuracy: 0.5870841487279843\n",
      "Done: 511, Accuracy: 0.5859375\n",
      "Done: 512, Accuracy: 0.5847953216374269\n",
      "Done: 513, Accuracy: 0.5836575875486382\n",
      "Done: 514, Accuracy: 0.5825242718446602\n",
      "Done: 515, Accuracy: 0.5813953488372093\n",
      "Done: 516, Accuracy: 0.5802707930367506\n",
      "Done: 517, Accuracy: 0.5791505791505791\n",
      "Done: 518, Accuracy: 0.5780346820809248\n",
      "Done: 519, Accuracy: 0.576923076923077\n",
      "Done: 520, Accuracy: 0.5758157389635317\n",
      "Done: 521, Accuracy: 0.5747126436781609\n",
      "Done: 522, Accuracy: 0.7648183556405354\n",
      "Done: 523, Accuracy: 0.7633587786259541\n",
      "Done: 524, Accuracy: 0.7619047619047619\n",
      "Done: 525, Accuracy: 0.7604562737642585\n",
      "Done: 526, Accuracy: 0.7590132827324478\n",
      "Done: 527, Accuracy: 0.7575757575757576\n",
      "Done: 528, Accuracy: 0.7561436672967864\n",
      "Done: 529, Accuracy: 0.7547169811320755\n",
      "Done: 530, Accuracy: 0.7532956685499058\n",
      "Done: 531, Accuracy: 0.7518796992481203\n",
      "Done: 532, Accuracy: 0.7504690431519699\n",
      "Done: 533, Accuracy: 0.7490636704119851\n",
      "Done: 534, Accuracy: 0.7476635514018692\n",
      "Done: 535, Accuracy: 0.7462686567164178\n",
      "Done: 536, Accuracy: 0.74487895716946\n",
      "Done: 537, Accuracy: 0.7434944237918215\n",
      "Done: 538, Accuracy: 0.7421150278293136\n",
      "Done: 539, Accuracy: 0.7407407407407408\n",
      "Done: 540, Accuracy: 0.7393715341959335\n",
      "Done: 541, Accuracy: 0.7380073800738007\n",
      "Done: 542, Accuracy: 0.7366482504604052\n",
      "Done: 543, Accuracy: 0.7352941176470588\n",
      "Done: 544, Accuracy: 0.7339449541284404\n",
      "Done: 545, Accuracy: 0.7326007326007326\n",
      "Done: 546, Accuracy: 0.7312614259597806\n",
      "Done: 547, Accuracy: 0.7299270072992701\n",
      "Done: 548, Accuracy: 0.7285974499089253\n",
      "Done: 549, Accuracy: 0.7272727272727273\n",
      "Done: 550, Accuracy: 0.7259528130671506\n",
      "Done: 551, Accuracy: 0.7246376811594203\n",
      "Done: 552, Accuracy: 0.7233273056057866\n",
      "Done: 553, Accuracy: 0.7220216606498195\n",
      "Done: 554, Accuracy: 0.7207207207207207\n",
      "Done: 555, Accuracy: 0.7194244604316548\n",
      "Done: 556, Accuracy: 0.718132854578097\n",
      "Done: 557, Accuracy: 0.7168458781362007\n",
      "Done: 558, Accuracy: 0.7155635062611807\n",
      "Done: 559, Accuracy: 0.7142857142857143\n",
      "Done: 560, Accuracy: 0.7130124777183601\n",
      "Done: 561, Accuracy: 0.7117437722419928\n",
      "Done: 562, Accuracy: 0.7104795737122558\n",
      "Done: 563, Accuracy: 0.7092198581560284\n",
      "Done: 564, Accuracy: 0.7079646017699115\n",
      "Done: 565, Accuracy: 0.7067137809187279\n",
      "Done: 566, Accuracy: 0.7054673721340388\n",
      "Done: 567, Accuracy: 0.7042253521126761\n",
      "Done: 568, Accuracy: 0.8787346221441126\n",
      "Done: 569, Accuracy: 0.8771929824561403\n",
      "Done: 570, Accuracy: 0.8756567425569177\n",
      "Done: 571, Accuracy: 0.8741258741258742\n",
      "Done: 572, Accuracy: 0.8726003490401396\n",
      "Done: 573, Accuracy: 0.8710801393728222\n",
      "Done: 574, Accuracy: 0.8695652173913043\n",
      "Done: 575, Accuracy: 0.8680555555555556\n",
      "Done: 576, Accuracy: 0.8665511265164645\n",
      "Done: 577, Accuracy: 0.8650519031141869\n",
      "Done: 578, Accuracy: 0.8635578583765112\n",
      "Done: 579, Accuracy: 0.8620689655172413\n",
      "Done: 580, Accuracy: 0.8605851979345954\n",
      "Done: 581, Accuracy: 0.859106529209622\n",
      "Done: 582, Accuracy: 0.8576329331046313\n",
      "Done: 583, Accuracy: 0.8561643835616438\n",
      "Done: 584, Accuracy: 0.8547008547008548\n",
      "Done: 585, Accuracy: 0.8532423208191127\n",
      "Done: 586, Accuracy: 0.8517887563884157\n",
      "Done: 587, Accuracy: 0.8503401360544218\n",
      "Done: 588, Accuracy: 0.8488964346349746\n",
      "Done: 589, Accuracy: 0.847457627118644\n",
      "Done: 590, Accuracy: 0.8460236886632826\n",
      "Done: 591, Accuracy: 0.8445945945945946\n",
      "Done: 592, Accuracy: 0.8431703204047217\n",
      "Done: 593, Accuracy: 0.8417508417508417\n",
      "Done: 594, Accuracy: 0.8403361344537815\n",
      "Done: 595, Accuracy: 0.8389261744966443\n",
      "Done: 596, Accuracy: 0.8375209380234505\n",
      "Done: 597, Accuracy: 0.8361204013377926\n",
      "Done: 598, Accuracy: 0.8347245409015025\n",
      "Done: 599, Accuracy: 0.8333333333333334\n",
      "Done: 600, Accuracy: 0.8319467554076538\n",
      "Done: 601, Accuracy: 0.8305647840531563\n",
      "Done: 602, Accuracy: 0.8291873963515755\n",
      "Done: 603, Accuracy: 0.8278145695364238\n",
      "Done: 604, Accuracy: 0.8264462809917356\n",
      "Done: 605, Accuracy: 0.825082508250825\n",
      "Done: 606, Accuracy: 0.8237232289950577\n",
      "Done: 607, Accuracy: 0.8223684210526315\n",
      "Done: 608, Accuracy: 0.8210180623973727\n",
      "Done: 609, Accuracy: 0.819672131147541\n",
      "Done: 610, Accuracy: 0.8183306055646482\n",
      "Done: 611, Accuracy: 0.8169934640522877\n",
      "Done: 612, Accuracy: 0.8156606851549755\n",
      "Done: 613, Accuracy: 0.8143322475570033\n",
      "Done: 614, Accuracy: 0.8130081300813009\n",
      "Done: 615, Accuracy: 0.8116883116883116\n",
      "Done: 616, Accuracy: 0.8103727714748784\n",
      "Done: 617, Accuracy: 0.8090614886731391\n",
      "Done: 618, Accuracy: 0.8077544426494345\n",
      "Done: 619, Accuracy: 0.8064516129032258\n",
      "Done: 620, Accuracy: 0.8051529790660225\n",
      "Done: 621, Accuracy: 0.8038585209003215\n",
      "Done: 622, Accuracy: 0.8025682182985553\n",
      "Done: 623, Accuracy: 0.8012820512820512\n",
      "Done: 624, Accuracy: 0.8\n",
      "Done: 625, Accuracy: 0.7987220447284344\n",
      "Done: 626, Accuracy: 0.7974481658692184\n",
      "Done: 627, Accuracy: 0.7961783439490446\n",
      "Done: 628, Accuracy: 0.7949125596184419\n",
      "Done: 629, Accuracy: 0.7936507936507936\n",
      "Done: 630, Accuracy: 0.7923930269413629\n",
      "Done: 631, Accuracy: 0.7911392405063291\n",
      "Done: 632, Accuracy: 0.7898894154818324\n",
      "Done: 633, Accuracy: 0.7886435331230284\n",
      "Done: 634, Accuracy: 0.7874015748031495\n",
      "Done: 635, Accuracy: 0.7861635220125787\n",
      "Done: 636, Accuracy: 0.7849293563579277\n",
      "Done: 637, Accuracy: 0.7836990595611284\n",
      "Done: 638, Accuracy: 0.7824726134585289\n",
      "Done: 639, Accuracy: 0.78125\n",
      "Done: 640, Accuracy: 0.7800312012480499\n",
      "Done: 641, Accuracy: 0.778816199376947\n",
      "Done: 642, Accuracy: 0.7776049766718507\n",
      "Done: 643, Accuracy: 0.7763975155279503\n",
      "Done: 644, Accuracy: 0.7751937984496124\n",
      "Done: 645, Accuracy: 0.7739938080495357\n",
      "Done: 646, Accuracy: 0.7727975270479135\n",
      "Done: 647, Accuracy: 0.7716049382716049\n",
      "Done: 648, Accuracy: 0.7704160246533128\n",
      "Done: 649, Accuracy: 0.7692307692307693\n",
      "Done: 650, Accuracy: 0.7680491551459293\n",
      "Done: 651, Accuracy: 0.7668711656441718\n",
      "Done: 652, Accuracy: 0.7656967840735069\n",
      "Done: 653, Accuracy: 0.764525993883792\n",
      "Done: 654, Accuracy: 0.7633587786259541\n",
      "Done: 655, Accuracy: 0.7621951219512195\n",
      "Done: 656, Accuracy: 0.76103500761035\n",
      "Done: 657, Accuracy: 0.7598784194528876\n",
      "Done: 658, Accuracy: 0.7587253414264037\n",
      "Done: 659, Accuracy: 0.7575757575757576\n",
      "Done: 660, Accuracy: 0.9077155824508321\n",
      "Done: 661, Accuracy: 0.906344410876133\n",
      "Done: 662, Accuracy: 0.904977375565611\n",
      "Done: 663, Accuracy: 0.9036144578313252\n",
      "Done: 664, Accuracy: 0.9022556390977444\n",
      "Done: 665, Accuracy: 0.9009009009009009\n",
      "Done: 666, Accuracy: 0.8995502248875562\n",
      "Done: 667, Accuracy: 0.8982035928143712\n",
      "Done: 668, Accuracy: 0.8968609865470852\n",
      "Done: 669, Accuracy: 0.8955223880597015\n",
      "Done: 670, Accuracy: 0.8941877794336811\n",
      "Done: 671, Accuracy: 0.8928571428571428\n",
      "Done: 672, Accuracy: 0.8915304606240713\n",
      "Done: 673, Accuracy: 0.8902077151335311\n",
      "Done: 674, Accuracy: 0.8888888888888888\n",
      "Done: 675, Accuracy: 0.8875739644970414\n",
      "Done: 676, Accuracy: 0.8862629246676514\n",
      "Done: 677, Accuracy: 0.8849557522123894\n",
      "Done: 678, Accuracy: 0.8836524300441826\n",
      "Done: 679, Accuracy: 0.8823529411764706\n",
      "Done: 680, Accuracy: 0.881057268722467\n",
      "Done: 681, Accuracy: 0.8797653958944283\n",
      "Done: 682, Accuracy: 0.8784773060029283\n",
      "Done: 683, Accuracy: 0.8771929824561403\n",
      "Done: 684, Accuracy: 0.8759124087591241\n",
      "Done: 685, Accuracy: 1.0204081632653061\n",
      "Done: 686, Accuracy: 1.0189228529839884\n",
      "Done: 687, Accuracy: 1.0174418604651163\n",
      "Done: 688, Accuracy: 1.0159651669085632\n",
      "Done: 689, Accuracy: 1.0144927536231882\n",
      "Done: 690, Accuracy: 1.0130246020260492\n",
      "Done: 691, Accuracy: 1.0115606936416186\n",
      "Done: 692, Accuracy: 1.0101010101010102\n",
      "Done: 693, Accuracy: 1.0086455331412103\n",
      "Done: 694, Accuracy: 1.0071942446043165\n",
      "Done: 695, Accuracy: 1.0057471264367817\n",
      "Done: 696, Accuracy: 1.0043041606886656\n",
      "Done: 697, Accuracy: 1.002865329512894\n",
      "Done: 698, Accuracy: 1.0014306151645207\n",
      "Done: 699, Accuracy: 1.0\n",
      "Done: 700, Accuracy: 0.9985734664764622\n",
      "Done: 701, Accuracy: 0.9971509971509971\n",
      "Done: 702, Accuracy: 0.995732574679943\n",
      "Done: 703, Accuracy: 0.9943181818181818\n",
      "Done: 704, Accuracy: 0.9929078014184398\n",
      "Done: 705, Accuracy: 0.9915014164305949\n",
      "Done: 706, Accuracy: 0.9900990099009901\n",
      "Done: 707, Accuracy: 0.9887005649717515\n",
      "Done: 708, Accuracy: 0.9873060648801129\n",
      "Done: 709, Accuracy: 0.9859154929577465\n",
      "Done: 710, Accuracy: 0.9845288326300985\n",
      "Done: 711, Accuracy: 0.9831460674157303\n",
      "Done: 712, Accuracy: 0.9817671809256662\n",
      "Done: 713, Accuracy: 0.9803921568627451\n",
      "Done: 714, Accuracy: 0.9790209790209791\n",
      "Done: 715, Accuracy: 0.9776536312849162\n",
      "Done: 716, Accuracy: 0.9762900976290098\n",
      "Done: 717, Accuracy: 0.9749303621169917\n",
      "Done: 718, Accuracy: 0.9735744089012517\n",
      "Done: 719, Accuracy: 0.9722222222222222\n",
      "Done: 720, Accuracy: 0.9708737864077669\n",
      "Done: 721, Accuracy: 0.9695290858725761\n",
      "Done: 722, Accuracy: 0.9681881051175657\n",
      "Done: 723, Accuracy: 0.9668508287292817\n",
      "Done: 724, Accuracy: 0.9655172413793104\n",
      "Done: 725, Accuracy: 0.9641873278236914\n",
      "Done: 726, Accuracy: 0.9628610729023385\n",
      "Done: 727, Accuracy: 0.9615384615384616\n",
      "Done: 728, Accuracy: 0.9602194787379973\n",
      "Done: 729, Accuracy: 0.9589041095890412\n",
      "Done: 730, Accuracy: 0.957592339261286\n",
      "Done: 731, Accuracy: 0.9562841530054645\n",
      "Done: 732, Accuracy: 0.9549795361527967\n",
      "Done: 733, Accuracy: 0.9536784741144414\n",
      "Done: 734, Accuracy: 0.9523809523809524\n",
      "Done: 735, Accuracy: 0.9510869565217392\n",
      "Done: 736, Accuracy: 0.9497964721845319\n",
      "Done: 737, Accuracy: 0.9485094850948509\n",
      "Done: 738, Accuracy: 0.9472259810554804\n",
      "Done: 739, Accuracy: 0.945945945945946\n",
      "Done: 740, Accuracy: 0.9446693657219973\n",
      "Done: 741, Accuracy: 0.9433962264150944\n",
      "Done: 742, Accuracy: 0.9421265141318977\n",
      "Done: 743, Accuracy: 0.9408602150537635\n",
      "Done: 744, Accuracy: 0.9395973154362416\n",
      "Done: 745, Accuracy: 0.938337801608579\n",
      "Done: 746, Accuracy: 0.9370816599732262\n",
      "Done: 747, Accuracy: 0.9358288770053476\n",
      "Done: 748, Accuracy: 0.9345794392523363\n",
      "Done: 749, Accuracy: 0.9333333333333335\n",
      "Done: 750, Accuracy: 0.9320905459387484\n",
      "Done: 751, Accuracy: 0.9308510638297872\n",
      "Done: 752, Accuracy: 0.9296148738379815\n",
      "Done: 753, Accuracy: 0.9283819628647214\n",
      "Done: 754, Accuracy: 0.9271523178807948\n",
      "Done: 755, Accuracy: 0.9259259259259258\n",
      "Done: 756, Accuracy: 0.9247027741083224\n",
      "Done: 757, Accuracy: 0.9234828496042217\n",
      "Done: 758, Accuracy: 0.922266139657444\n",
      "Done: 759, Accuracy: 0.9210526315789472\n",
      "Done: 760, Accuracy: 0.9198423127463863\n",
      "Done: 761, Accuracy: 0.9186351706036745\n",
      "Done: 762, Accuracy: 0.9174311926605505\n",
      "Done: 763, Accuracy: 0.9162303664921465\n",
      "Done: 764, Accuracy: 0.9150326797385622\n",
      "Done: 765, Accuracy: 0.9138381201044387\n",
      "Done: 766, Accuracy: 0.9126466753585397\n",
      "Done: 767, Accuracy: 0.9114583333333334\n",
      "Done: 768, Accuracy: 0.9102730819245773\n",
      "Done: 769, Accuracy: 0.9090909090909091\n",
      "Done: 770, Accuracy: 0.9079118028534372\n",
      "Done: 771, Accuracy: 0.9067357512953367\n",
      "Done: 772, Accuracy: 0.9055627425614489\n",
      "Done: 773, Accuracy: 0.9043927648578811\n",
      "Done: 774, Accuracy: 0.903225806451613\n",
      "Done: 775, Accuracy: 0.902061855670103\n",
      "Done: 776, Accuracy: 0.9009009009009009\n",
      "Done: 777, Accuracy: 0.8997429305912596\n",
      "Done: 778, Accuracy: 0.8985879332477535\n",
      "Done: 779, Accuracy: 0.8974358974358974\n",
      "Done: 780, Accuracy: 0.8962868117797695\n",
      "Done: 781, Accuracy: 0.8951406649616368\n",
      "Done: 782, Accuracy: 0.8939974457215836\n",
      "Done: 783, Accuracy: 0.8928571428571428\n",
      "Done: 784, Accuracy: 0.89171974522293\n",
      "Done: 785, Accuracy: 0.8905852417302799\n",
      "Done: 786, Accuracy: 0.8894536213468869\n",
      "Done: 787, Accuracy: 0.8883248730964468\n",
      "Done: 788, Accuracy: 0.8871989860583016\n",
      "Done: 789, Accuracy: 0.8860759493670887\n",
      "Done: 790, Accuracy: 0.8849557522123894\n",
      "Done: 791, Accuracy: 0.8838383838383838\n",
      "Done: 792, Accuracy: 0.8827238335435058\n",
      "Done: 793, Accuracy: 0.8816120906801008\n",
      "Done: 794, Accuracy: 0.8805031446540881\n",
      "Done: 795, Accuracy: 0.8793969849246231\n",
      "Done: 796, Accuracy: 0.8782936010037641\n",
      "Done: 797, Accuracy: 0.8771929824561403\n",
      "Done: 798, Accuracy: 0.8760951188986232\n",
      "Done: 799, Accuracy: 0.8750000000000001\n",
      "Done: 800, Accuracy: 0.8739076154806492\n",
      "Done: 801, Accuracy: 0.8728179551122194\n",
      "Done: 802, Accuracy: 0.8717310087173101\n",
      "Done: 803, Accuracy: 0.8706467661691543\n",
      "Done: 804, Accuracy: 0.8695652173913043\n",
      "Done: 805, Accuracy: 0.8684863523573202\n",
      "Done: 806, Accuracy: 0.8674101610904585\n",
      "Done: 807, Accuracy: 0.8663366336633664\n",
      "Done: 808, Accuracy: 0.865265760197775\n",
      "Done: 809, Accuracy: 0.8641975308641975\n",
      "Done: 810, Accuracy: 0.8631319358816275\n",
      "Done: 811, Accuracy: 0.8620689655172413\n",
      "Done: 812, Accuracy: 0.8610086100861009\n",
      "Done: 813, Accuracy: 0.85995085995086\n",
      "Done: 814, Accuracy: 0.8588957055214724\n",
      "Done: 815, Accuracy: 0.857843137254902\n",
      "Done: 816, Accuracy: 0.8567931456548347\n",
      "Done: 817, Accuracy: 0.8557457212713936\n",
      "Done: 818, Accuracy: 0.8547008547008548\n",
      "Done: 819, Accuracy: 0.853658536585366\n",
      "Done: 820, Accuracy: 0.8526187576126675\n",
      "Done: 821, Accuracy: 0.851581508515815\n",
      "Done: 822, Accuracy: 0.850546780072904\n",
      "Done: 823, Accuracy: 0.8495145631067961\n",
      "Done: 824, Accuracy: 0.8484848484848486\n",
      "Done: 825, Accuracy: 0.847457627118644\n",
      "Done: 826, Accuracy: 0.8464328899637243\n",
      "Done: 827, Accuracy: 0.8454106280193237\n",
      "Done: 828, Accuracy: 0.8443908323281062\n",
      "Done: 829, Accuracy: 0.8433734939759037\n",
      "Done: 830, Accuracy: 0.842358604091456\n",
      "Done: 831, Accuracy: 0.8413461538461539\n",
      "Done: 832, Accuracy: 0.8403361344537815\n",
      "Done: 833, Accuracy: 0.8393285371702638\n",
      "Done: 834, Accuracy: 0.8383233532934131\n",
      "Done: 835, Accuracy: 0.8373205741626795\n",
      "Done: 836, Accuracy: 0.8363201911589008\n",
      "Done: 837, Accuracy: 0.8353221957040573\n",
      "Done: 838, Accuracy: 0.834326579261025\n",
      "Done: 839, Accuracy: 0.8333333333333334\n",
      "Done: 840, Accuracy: 0.8323424494649228\n",
      "Done: 841, Accuracy: 0.831353919239905\n",
      "Done: 842, Accuracy: 0.8303677342823249\n",
      "Done: 843, Accuracy: 0.8293838862559242\n",
      "Done: 844, Accuracy: 0.8284023668639053\n",
      "Done: 845, Accuracy: 0.8274231678486997\n",
      "Done: 846, Accuracy: 0.8264462809917356\n",
      "Done: 847, Accuracy: 0.8254716981132075\n",
      "Done: 848, Accuracy: 0.8244994110718492\n",
      "Done: 849, Accuracy: 0.823529411764706\n",
      "Done: 850, Accuracy: 0.8225616921269095\n",
      "Done: 851, Accuracy: 0.8215962441314555\n",
      "Done: 852, Accuracy: 0.8206330597889802\n",
      "Done: 853, Accuracy: 0.819672131147541\n",
      "Done: 854, Accuracy: 0.9356725146198831\n",
      "Done: 855, Accuracy: 0.9345794392523363\n",
      "Done: 856, Accuracy: 0.9334889148191364\n",
      "Done: 857, Accuracy: 0.9324009324009324\n",
      "Done: 858, Accuracy: 0.9313154831199069\n",
      "Done: 859, Accuracy: 0.9302325581395349\n",
      "Done: 860, Accuracy: 0.9291521486643438\n",
      "Done: 861, Accuracy: 0.9280742459396751\n",
      "Done: 862, Accuracy: 0.9269988412514484\n",
      "Done: 863, Accuracy: 0.9259259259259258\n",
      "Done: 864, Accuracy: 0.9248554913294799\n",
      "Done: 865, Accuracy: 0.9237875288683602\n",
      "Done: 866, Accuracy: 0.922722029988466\n",
      "Done: 867, Accuracy: 0.9216589861751152\n",
      "Done: 868, Accuracy: 0.9205983889528193\n",
      "Done: 869, Accuracy: 0.9195402298850575\n",
      "Done: 870, Accuracy: 0.9184845005740528\n",
      "Done: 871, Accuracy: 0.9174311926605505\n",
      "Done: 872, Accuracy: 0.9163802978235969\n",
      "Done: 873, Accuracy: 0.9153318077803204\n",
      "Done: 874, Accuracy: 0.9142857142857144\n",
      "Done: 875, Accuracy: 0.91324200913242\n",
      "Done: 876, Accuracy: 0.9122006841505131\n",
      "Done: 877, Accuracy: 0.9111617312072893\n",
      "Done: 878, Accuracy: 0.9101251422070534\n",
      "Done: 879, Accuracy: 0.9090909090909091\n",
      "Done: 880, Accuracy: 0.9080590238365494\n",
      "Done: 881, Accuracy: 0.9070294784580499\n",
      "Done: 882, Accuracy: 0.9060022650056626\n",
      "Done: 883, Accuracy: 0.904977375565611\n",
      "Done: 884, Accuracy: 0.903954802259887\n",
      "Done: 885, Accuracy: 0.9029345372460496\n",
      "Done: 886, Accuracy: 0.9019165727170236\n",
      "Done: 887, Accuracy: 0.9009009009009009\n",
      "Done: 888, Accuracy: 0.8998875140607425\n",
      "Done: 889, Accuracy: 0.8988764044943821\n",
      "Done: 890, Accuracy: 0.8978675645342313\n",
      "Done: 891, Accuracy: 0.8968609865470852\n",
      "Done: 892, Accuracy: 0.8958566629339306\n",
      "Done: 893, Accuracy: 0.8948545861297539\n",
      "Done: 894, Accuracy: 0.8938547486033519\n",
      "Done: 895, Accuracy: 0.8928571428571428\n",
      "Done: 896, Accuracy: 0.8918617614269788\n",
      "Done: 897, Accuracy: 0.8908685968819599\n",
      "Done: 898, Accuracy: 0.8898776418242491\n",
      "Done: 899, Accuracy: 0.8888888888888888\n",
      "Done: 900, Accuracy: 0.8879023307436182\n",
      "Done: 901, Accuracy: 0.8869179600886918\n",
      "Done: 902, Accuracy: 0.8859357696566998\n",
      "Done: 903, Accuracy: 0.8849557522123894\n",
      "Done: 904, Accuracy: 0.8839779005524863\n",
      "Done: 905, Accuracy: 0.8830022075055187\n",
      "Done: 906, Accuracy: 0.8820286659316428\n",
      "Done: 907, Accuracy: 0.881057268722467\n",
      "Done: 908, Accuracy: 0.88008800880088\n",
      "Done: 909, Accuracy: 0.8791208791208791\n",
      "Done: 910, Accuracy: 0.8781558726673985\n",
      "Done: 911, Accuracy: 0.8771929824561403\n",
      "Done: 912, Accuracy: 0.8762322015334063\n",
      "Done: 913, Accuracy: 0.87527352297593\n",
      "Done: 914, Accuracy: 0.8743169398907104\n",
      "Done: 915, Accuracy: 0.8733624454148471\n",
      "Done: 916, Accuracy: 0.8724100327153763\n",
      "Done: 917, Accuracy: 0.8714596949891068\n",
      "Done: 918, Accuracy: 0.9793253536452665\n",
      "Done: 919, Accuracy: 0.9782608695652175\n",
      "Done: 920, Accuracy: 0.9771986970684038\n",
      "Done: 921, Accuracy: 0.9761388286334056\n",
      "Done: 922, Accuracy: 0.9750812567713976\n",
      "Done: 923, Accuracy: 0.974025974025974\n",
      "Done: 924, Accuracy: 0.9729729729729729\n",
      "Done: 925, Accuracy: 0.9719222462203023\n",
      "Done: 926, Accuracy: 0.9708737864077669\n",
      "Done: 927, Accuracy: 0.9698275862068966\n",
      "Done: 928, Accuracy: 0.9687836383207751\n",
      "Done: 929, Accuracy: 0.967741935483871\n",
      "Done: 930, Accuracy: 0.966702470461869\n",
      "Done: 931, Accuracy: 0.9656652360515022\n",
      "Done: 932, Accuracy: 0.964630225080386\n",
      "Done: 933, Accuracy: 0.9635974304068522\n",
      "Done: 934, Accuracy: 0.9625668449197862\n",
      "Done: 935, Accuracy: 0.9615384615384616\n",
      "Done: 936, Accuracy: 0.96051227321238\n",
      "Done: 937, Accuracy: 0.9594882729211088\n",
      "Done: 938, Accuracy: 0.9584664536741214\n",
      "Done: 939, Accuracy: 0.9574468085106382\n",
      "Done: 940, Accuracy: 0.9564293304994688\n",
      "Done: 941, Accuracy: 0.9554140127388535\n",
      "Done: 942, Accuracy: 0.9544008483563097\n",
      "Done: 943, Accuracy: 0.9533898305084746\n",
      "Done: 944, Accuracy: 0.9523809523809524\n",
      "Done: 945, Accuracy: 0.9513742071881607\n",
      "Done: 946, Accuracy: 0.9503695881731784\n",
      "Done: 947, Accuracy: 0.949367088607595\n",
      "Done: 948, Accuracy: 0.9483667017913594\n",
      "Done: 949, Accuracy: 0.9473684210526316\n",
      "Done: 950, Accuracy: 0.9463722397476341\n",
      "Done: 951, Accuracy: 1.050420168067227\n",
      "Done: 952, Accuracy: 1.049317943336831\n",
      "Done: 953, Accuracy: 1.0482180293501049\n",
      "Done: 954, Accuracy: 1.0471204188481675\n",
      "Done: 955, Accuracy: 1.0460251046025104\n",
      "Done: 956, Accuracy: 1.044932079414838\n",
      "Done: 957, Accuracy: 1.0438413361169103\n",
      "Done: 958, Accuracy: 1.0427528675703857\n",
      "Done: 959, Accuracy: 1.0416666666666665\n",
      "Done: 960, Accuracy: 1.040582726326743\n",
      "Done: 961, Accuracy: 1.0395010395010396\n",
      "Done: 962, Accuracy: 1.0384215991692627\n",
      "Done: 963, Accuracy: 1.0373443983402488\n",
      "Done: 964, Accuracy: 1.0362694300518136\n",
      "Done: 965, Accuracy: 1.0351966873706004\n",
      "Done: 966, Accuracy: 1.0341261633919339\n",
      "Done: 967, Accuracy: 1.0330578512396695\n",
      "Done: 968, Accuracy: 1.0319917440660475\n",
      "Done: 969, Accuracy: 1.0309278350515463\n",
      "Done: 970, Accuracy: 1.0298661174047374\n",
      "Done: 971, Accuracy: 1.02880658436214\n",
      "Done: 972, Accuracy: 1.027749229188078\n",
      "Done: 973, Accuracy: 1.0266940451745379\n",
      "Done: 974, Accuracy: 1.0256410256410255\n",
      "Done: 975, Accuracy: 1.0245901639344261\n",
      "Done: 976, Accuracy: 1.023541453428864\n",
      "Done: 977, Accuracy: 1.0224948875255624\n",
      "Done: 978, Accuracy: 1.0214504596527068\n",
      "Done: 979, Accuracy: 1.0204081632653061\n",
      "Done: 980, Accuracy: 1.019367991845056\n",
      "Done: 981, Accuracy: 1.0183299389002036\n",
      "Done: 982, Accuracy: 1.017293997965412\n",
      "Done: 983, Accuracy: 1.0162601626016259\n",
      "Done: 984, Accuracy: 1.015228426395939\n",
      "Done: 985, Accuracy: 1.0141987829614605\n",
      "Done: 986, Accuracy: 1.0131712259371835\n",
      "Done: 987, Accuracy: 1.0121457489878543\n",
      "Done: 988, Accuracy: 1.0111223458038423\n",
      "Done: 989, Accuracy: 1.0101010101010102\n",
      "Done: 990, Accuracy: 1.0090817356205852\n",
      "Done: 991, Accuracy: 1.0080645161290323\n",
      "Done: 992, Accuracy: 1.0070493454179255\n",
      "Done: 993, Accuracy: 1.0060362173038229\n",
      "Done: 994, Accuracy: 1.0050251256281406\n",
      "Done: 995, Accuracy: 1.0040160642570282\n",
      "Done: 996, Accuracy: 1.0030090270812437\n",
      "Done: 997, Accuracy: 1.002004008016032\n",
      "Done: 998, Accuracy: 1.001001001001001\n",
      "Done: 999, Accuracy: 1.0\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# n_components = [5000]\n",
    "\n",
    "\n",
    "# def do(X_test_scaled):\n",
    "#     accuracy = getAccuracy(10, X_test_scaled, testData, winSize, (8,8), (4,4), (2,2), 12)\n",
    "#     print(f\"n: {n}, Accuracy: {accuracy}\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")\n",
    "\n",
    "# threads = []\n",
    "# for n in n_components:\n",
    "#     pca = PCA(n_components=n)\n",
    "#     pca.fit_transform(X_train_scaled)\n",
    "#     pca.transform(X_test_scaled)\n",
    "#     # threads.append(threading.Thread(target=do, args=(np.array(X_test_scaled),) ))\n",
    "#     # threads[len(threads)-1].start()\n",
    "#     accuracy = getAccuracy(10, X_test_scaled, testData, winSize, (8,8), (4,4), (2,2), 12)\n",
    "#     print(f\"n: {n}, Accuracy: {accuracy}\")\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit_transform(X_train_scaled, y_train)\n",
    "accuracy = getAccuracy(10, X_test_scaled, testData, winSize, (8,8), (4,4), (2,2), 12)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "    \n",
    "# for t in threads:\n",
    "#     t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac1d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(grid_search.cv_results_)\n",
    "# print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33a7464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:58:03.255363Z",
     "iopub.status.busy": "2022-12-05T22:58:03.253532Z",
     "iopub.status.idle": "2022-12-05T22:58:03.328054Z",
     "shell.execute_reply": "2022-12-05T22:58:03.326424Z"
    },
    "papermill": {
     "duration": 0.146555,
     "end_time": "2022-12-05T22:58:03.330908",
     "exception": false,
     "start_time": "2022-12-05T22:58:03.184353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3225649/3796635586.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  TruePreds.append(subCategory.iloc[testData['fine_labels'][i]][0].capitalize())\n"
     ]
    }
   ],
   "source": [
    "TruePreds = []\n",
    "\n",
    "for i in range(1000):\n",
    "    TruePreds.append(subCategory.iloc[testData['fine_labels'][i]][0].capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14925919",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:58:03.475960Z",
     "iopub.status.busy": "2022-12-05T22:58:03.475212Z",
     "iopub.status.idle": "2022-12-05T22:58:03.480728Z",
     "shell.execute_reply": "2022-12-05T22:58:03.479576Z"
    },
    "papermill": {
     "duration": 0.085121,
     "end_time": "2022-12-05T22:58:03.483477",
     "exception": false,
     "start_time": "2022-12-05T22:58:03.398356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predicted = []\n",
    "# for i in range(len(Preds14)):\n",
    "#     Predicted.append(Preds14[i][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0efbc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:58:03.619116Z",
     "iopub.status.busy": "2022-12-05T22:58:03.618550Z",
     "iopub.status.idle": "2022-12-05T22:58:03.630683Z",
     "shell.execute_reply": "2022-12-05T22:58:03.629447Z"
    },
    "papermill": {
     "duration": 0.083269,
     "end_time": "2022-12-05T22:58:03.633836",
     "exception": false,
     "start_time": "2022-12-05T22:58:03.550567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(TruePreds, Predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cf1307",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:58:03.768143Z",
     "iopub.status.busy": "2022-12-05T22:58:03.767707Z",
     "iopub.status.idle": "2022-12-05T22:58:03.775658Z",
     "shell.execute_reply": "2022-12-05T22:58:03.774338Z"
    },
    "papermill": {
     "duration": 0.07769,
     "end_time": "2022-12-05T22:58:03.778111",
     "exception": false,
     "start_time": "2022-12-05T22:58:03.700421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x = np.array(TruePreds)\n",
    "# len(np.unique(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40403655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:58:03.914918Z",
     "iopub.status.busy": "2022-12-05T22:58:03.914111Z",
     "iopub.status.idle": "2022-12-05T22:58:03.921861Z",
     "shell.execute_reply": "2022-12-05T22:58:03.920647Z"
    },
    "papermill": {
     "duration": 0.079024,
     "end_time": "2022-12-05T22:58:03.924973",
     "exception": false,
     "start_time": "2022-12-05T22:58:03.845949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cm_df = pd.DataFrame(cm,\n",
    "#                      index = np.unique(x), \n",
    "#                      columns = np.unique(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed65b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T22:58:04.067590Z",
     "iopub.status.busy": "2022-12-05T22:58:04.067060Z",
     "iopub.status.idle": "2022-12-05T22:58:34.985070Z",
     "shell.execute_reply": "2022-12-05T22:58:34.983788Z"
    },
    "papermill": {
     "duration": 31.068754,
     "end_time": "2022-12-05T22:58:35.063213",
     "exception": false,
     "start_time": "2022-12-05T22:58:03.994459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16,16))\n",
    "# sns.heatmap(cm_df, annot=True)\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.ylabel('Actal Values')\n",
    "# plt.xlabel('Predicted Values')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1324.995076,
   "end_time": "2022-12-05T22:58:38.304437",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-05T22:36:33.309361",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
